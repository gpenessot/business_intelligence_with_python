{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Advanced Data Processing\n",
    "## 3.3.1 Outliers\n",
    "\n",
    "Define functions to handle outliers using IQR method:\n",
    "\n",
    "```python\n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "\n",
    "def filter_outliers(df, column_name):     \n",
    "    data = df[column_name]     \n",
    "    Q1 = np.percentile(data, 25)     \n",
    "    Q3 = np.percentile(data, 75)     \n",
    "    IQR = Q3 - Q1     \n",
    "    lower_bound = Q1 - 1.5 * IQR     \n",
    "    upper_bound = Q3 + 1.5 * IQR          \n",
    "    filtered_data = (\n",
    "        df[(df[column_name] >= lower_bound) & \n",
    "        (df[column_name] <= upper_bound)]\n",
    "    )          \n",
    "    return filtered_data\n",
    "```\n",
    "\n",
    "Handle outliers using Z-score method:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "\n",
    "def filter_outliers_zscore(df, column_name):     \n",
    "    data = df[column_name]     \n",
    "    mean = np.mean(data)     \n",
    "    std = np.std(data)     \n",
    "    threshold = 3          \n",
    "    z_scores = [(x - mean) / std for x in data]     \n",
    "    filtered_data = df[abs(z_scores) <= threshold]          \n",
    "    return filtered_data\n",
    "```\n",
    "\n",
    "Cap values using clip method:\n",
    "\n",
    "```python\n",
    "import pandas as pd \n",
    "\n",
    "def cap_missing_values(column, lower_cap, upper_cap):\n",
    "    \"\"\"\n",
    "    Apply capping to missing values based on specified lower and upper caps using Pandas clip method.\n",
    "\n",
    "    Parameters:\n",
    "    - column: Pandas Series representing a column of numerical data\n",
    "    - lower_cap: Value to cap below\n",
    "    - upper_cap: Value to cap above\n",
    "\n",
    "    Returns:\n",
    "    - capped_column: Column with missing values capped based on lower and upper caps\n",
    "    \"\"\"\n",
    "    # Apply clip method to cap values\n",
    "    capped_column = column.clip(lower=lower_cap, upper=upper_cap)\n",
    "    \n",
    "    return capped_column\n",
    "```\n",
    "\n",
    "## 3.3.2 Approximate Values\n",
    "\n",
    "Using TheFuzz for fuzzy string matching:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'country': ['USA', 'US', 'USA', 'usa', 'France', 'FRANCE', 'fraNce', 'SpAIn', 'Spain','spain', 'SPAIN', 'CaNAda', 'canada', 'CANADA']\n",
    "})\n",
    "\n",
    "ref_list = ['France', 'USA', 'Canada', 'Spain']\n",
    "\n",
    "def fuzzy_grouping(df, col_name, ref_list=ref_list, threshold=80):\n",
    "    mappings = {}\n",
    "\n",
    "    for ref_val in ref_list:\n",
    "        close_matches = process.extract(ref_val, \n",
    "                                        df[col_name].unique(),\n",
    "                                        scorer=fuzz.token_set_ratio, \n",
    "                                        limit=None)\n",
    "        close_matches = [matches[0] for matches in close_matches if matches[1] >= threshold]\n",
    "\n",
    "        for matches in close_matches:\n",
    "            mappings[matches] = ref_val\n",
    "\n",
    "    df['corrected_value'] = df[col_name].map(mappings)\n",
    "    df_grouped = df.groupby('corrected_value')[col_name].unique().reset_index()\n",
    "    df_grouped.columns = ['value', 'mispelled_values']\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "grouped_df = fuzzy_grouping(df, 'country', threshold=60)\n",
    "print(grouped_df)\n",
    "```\n",
    "\n",
    "Using RecordLinkage for data matching:\n",
    "\n",
    "```python\n",
    "# Importation des bibliothèques nécessaire\n",
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "# Load datasets\n",
    "df1 = pd.read_csv('datasets1.csv')\n",
    "df2 = pd.read_csv('datasets2.csv')\n",
    "\n",
    "# Create an indexer\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block('client_index') # Column used for linkage\n",
    "candidate_links = indexer.index(df1, df2)\n",
    "\n",
    "# Create compare object\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "# Add columns to compare\n",
    "compare.string('client_phone_number', \n",
    "               'client_phone_number', \n",
    "               method='jarowinkler', \n",
    "               threshold=0.85)\n",
    "\n",
    "# Compare datasets\n",
    "features = compare.compute(candidate_links, df1, df2)\n",
    "\n",
    "# Find matches\n",
    "matches = features[features.sum(axis=1) >= 3]\n",
    "\n",
    "# Transform indexes to dataframe and merge with original dataframes\n",
    "matches.reset_index(inplace=True)\n",
    "final_df = (\n",
    "            pd.merge(matches, \n",
    "                    df1,  \n",
    "                    how='left', \n",
    "                    left_on=['client_phone_number'], \n",
    "                    right_on = ['client_phone_number'])\n",
    "              .merge(df2, \n",
    "                     how='left', \n",
    "                     left_on=['client_phone_number'], \n",
    "                     right_on = ['client_phone_number'])\n",
    "```\n",
    "\n",
    "## 3.3.3 Time Series\n",
    "\n",
    "Convert dates and handle missing values in time series:\n",
    "\n",
    "```python\n",
    "import pandas as pd  \n",
    "# Convert date column to datetime and set as index\n",
    "df['date'] = pd.to_datetime(df['date'], format=\"%d/%m/%Y\") \n",
    "df = df.set_index('date')\n",
    "\n",
    "# Set frequency and use forward fill method to fill NaN\n",
    "df = df.as_freq('D').fillna(method='ffil')\n",
    "```\n",
    "\n",
    "Extract features from datetime:\n",
    "\n",
    "```python\n",
    "# Extract features from date field\n",
    "df['year'] = df['date'].dt.year # year\n",
    "df['month'] = df['date'].dt.month # month\n",
    "df['day_of_week'] = df['date'].dt.dayofweek # day of week (monday=0)\n",
    "```\n",
    "\n",
    "Check time series continuity:\n",
    "\n",
    "```python\n",
    "# Check continuity by examining time intervals between data points\n",
    "gaps = df.index.to_series().diff().dt.days > 1 \n",
    "# Here, 'gaps' is a boolean series indicating where there are discontinuities\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
